Project Proposal Management Plan: The Ethical Implications of DeepSeek AI Censorship
Introduction
Artificial Intelligence (AI) is transforming how people access and interact with information. However, in certain political environments, AI models are subjected to strict censorship regulations, limiting their ability to provide unbiased information. DeepSeek AI, a chatbot based in China, exemplifies this issue by restricting access to politically sensitive topics such as the Tiananmen Square protests, Taiwan’s sovereignty, and the treatment of Uighurs. These restrictions raise significant ethical concerns regarding transparency, access to information, and the responsibility of AI developers.

This project aims to analyze DeepSeek AI’s censorship framework, the political and economic motivations behind it, and its impact on public knowledge. Through a structured research approach, the study will assess the ethical dilemmas faced by AI companies operating in restrictive environments and propose solutions for balancing compliance with transparency.

Objectives
The primary objective of this project is to investigate the extent of DeepSeek AI’s censorship and its implications for users and society. Specifically, the research will:

Analyze the Censorship Framework – Examine how DeepSeek AI censors politically sensitive content and the regulatory policies influencing these restrictions.
Evaluate the Ethical Dilemmas – Investigate the conflict between government-mandated censorship and the ethical responsibility of AI companies to provide unbiased information.
Assess the Impact on Users – Determine how censorship affects public knowledge, global discourse, and access to diverse perspectives.
Propose Solutions – Develop recommendations for AI companies to balance government compliance with ethical information dissemination.
By achieving these objectives, the study will contribute to discussions on AI governance, digital rights, and the ethical considerations surrounding information control.

Project Scope
This project will focus on AI censorship in China, using DeepSeek AI as a case study to highlight the broader implications of government-controlled digital platforms. The research will be conducted through a combination of literature review, legal analysis, ethical evaluations, and case study examinations. Additionally, the study will incorporate perspectives from international AI governance frameworks to provide a comparative analysis. The findings will be compiled into a research report and summarized in a visual research poster for academic presentation.

Timeline and Milestones
The project will be carried out over several phases, each focusing on specific research and development aspects. The estimated timeline for completion is outlined as follows:

Phase 1: Research & Planning (Weeks 1–3)

Conduct a literature review on AI censorship practices and policies.
Gather data on DeepSeek AI’s censorship mechanisms.
Develop the theoretical framework for analysis.
Phase 2: Data Analysis (Weeks 4–7)

Evaluate case studies of AI censorship.
Analyze ethical dilemmas using theoretical frameworks such as utilitarianism, Kantian ethics, and stakeholder theory.
Assess the impact of censorship on users and society.
Phase 3: Solution Development (Weeks 8–10)

Formulate recommendations for AI companies regarding transparency and ethical compliance.
Compare different models of AI governance and censorship mitigation.
Phase 4: Finalization & Presentation (Weeks 11–12)

Compile findings into a structured research report.
Design and develop a research poster for academic presentation.
Conduct peer reviews and finalize the project.
The timeline ensures a systematic approach to data collection, analysis, and dissemination, allowing for a comprehensive examination of DeepSeek AI’s censorship policies.

Required Resources
To successfully complete this project, a range of human, material, and financial resources will be required.

Human Resources:
Researcher: Responsible for conducting the analysis, compiling the research, and drafting the final report.
Advisor/Supervisor: Provides academic guidance, feedback, and recommendations throughout the research process.
Peer Reviewers: Assist in evaluating the research findings and ensuring the credibility and accuracy of the study.

Material & Technological Resources:
Hardware: A laptop or desktop computer for research, data analysis, and documentation.
Software: Microsoft Word for report writing, PowerPoint or Canva for poster design, and possible use of Python if implementing AI-based censorship detection.
Online Resources: Access to academic journals, legal documents, censorship reports, and AI governance policies.

Financial Resources (If applicable):
Subscriptions: Access to premium research databases if required.
Printing Costs: Expenses for printing the research poster and final report for academic submission.
These resources will ensure that the research is conducted efficiently and that findings are presented effectively.
